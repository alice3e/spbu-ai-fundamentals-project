{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0454116b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 1.6.1\n",
      "xgboost version: 3.0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib # Часто лучше для объектов scikit-learn\n",
    "import json\n",
    "import re # Для обработки времени выполнения\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import category_encoders as ce # Для TargetEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "import sklearn\n",
    "import xgboost\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"xgboost version: {xgboost.__version__}\")\n",
    "\n",
    "\n",
    "# Настройки для воспроизводимости\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Настройки отображения pandas и matplotlib\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "212aff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные успешно загружены.\n",
      "Размер исходных данных: (5719, 24)\n",
      "Первые 5 строк:\n",
      "    movie_id     movie_title  movie_year            director          writer  \\\n",
      "0  tt0118589         Glitter        2001  Vondie Curtis-Hall  Cheryl L. West   \n",
      "1  tt0120630     Chicken Run        2000          Peter Lord      Peter Lord   \n",
      "2  tt0120667  Fantastic Four        2005           Tim Story      Mark Frost   \n",
      "3  tt0120679           Frida        2002        Julie Taymor  Hayden Herrera   \n",
      "4  tt0120681       From Hell        2001       Albert Hughes      Alan Moore   \n",
      "\n",
      "             producer                composer   cinematographer  \\\n",
      "0       Laurence Mark       Terence Blanchard  Geoffrey Simpson   \n",
      "1          Peter Lord  Harry Gregson-Williams      Simon Jacobs   \n",
      "2            Avi Arad             John Ottman       Oliver Wood   \n",
      "3  Lindsay Flickinger       Elliot Goldenthal    Rodrigo Prieto   \n",
      "4        Jane Hamsher            Trevor Jones      Peter Deming   \n",
      "\n",
      "    main_actor_1     main_actor_2   main_actor_3     main_actor_4     budget  \\\n",
      "0   Mariah Carey       Eric Benét    Max Beesley          Da Brat   22000000   \n",
      "1     Mel Gibson    Julia Sawalha   Phil Daniels    Lynn Ferguson   45000000   \n",
      "2  Ioan Gruffudd  Michael Chiklis    Chris Evans     Jessica Alba  100000000   \n",
      "3    Salma Hayek    Alfred Molina  Geoffrey Rush      Mía Maestro   12000000   \n",
      "4    Johnny Depp   Heather Graham       Ian Holm  Robbie Coltrane   35000000   \n",
      "\n",
      "      domestic  international    worldwide   mpaa     run_time    genre_1  \\\n",
      "0    4274407.0       997259.0    5271666.0  PG-13  1 hr 44 min      Drama   \n",
      "1  106834564.0    118000000.0  224834564.0    NaN  1 hr 24 min  Adventure   \n",
      "2  154696080.0    178839854.0  333535934.0  PG-13  1 hr 46 min     Action   \n",
      "3   25885000.0     30413474.0   56298474.0      R   2 hr 3 min  Biography   \n",
      "4   31602566.0     42955549.0   74558115.0      R   2 hr 2 min     Horror   \n",
      "\n",
      "     genre_2   genre_3  genre_4  \\\n",
      "0      Music   Romance      NaN   \n",
      "1  Animation    Comedy    Drama   \n",
      "2  Adventure    Family  Fantasy   \n",
      "3      Drama   Romance      NaN   \n",
      "4    Mystery  Thriller      NaN   \n",
      "\n",
      "                                                link distributor  \n",
      "0  https://www.boxofficemojo.com/title/tt0118589/...         NaN  \n",
      "1  https://www.boxofficemojo.com/title/tt0120630/...         NaN  \n",
      "2  https://www.boxofficemojo.com/title/tt0120667/...         NaN  \n",
      "3  https://www.boxofficemojo.com/title/tt0120679/...         NaN  \n",
      "4  https://www.boxofficemojo.com/title/tt0120681/...         NaN  \n",
      "\n",
      "Процент пропусков в столбцах (топ 24):\n",
      "        column_name  percentage\n",
      "21          genre_4   64.574226\n",
      "23      distributor   43.556566\n",
      "20          genre_3   30.914496\n",
      "19          genre_2    8.078335\n",
      "14    international    7.169086\n",
      "16             mpaa    3.899283\n",
      "7   cinematographer    3.567057\n",
      "6          composer    3.112432\n",
      "13         domestic    0.332226\n",
      "5          producer    0.314740\n",
      "4            writer    0.227312\n",
      "15        worldwide    0.122399\n",
      "11     main_actor_4    0.052457\n",
      "22             link    0.000000\n",
      "18          genre_1    0.000000\n",
      "17         run_time    0.000000\n",
      "0          movie_id    0.000000\n",
      "1       movie_title    0.000000\n",
      "10     main_actor_3    0.000000\n",
      "9      main_actor_2    0.000000\n",
      "8      main_actor_1    0.000000\n",
      "3          director    0.000000\n",
      "2        movie_year    0.000000\n",
      "12           budget    0.000000\n",
      "\n",
      "Удалено 7 строк из-за отсутствия значения в 'worldwide'.\n",
      "Размер данных после удаления строк с NaN в 'worldwide': (5712, 24)\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "try:\n",
    "    data = pd.read_csv(\"../data/all_data.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Файл ../data/all_data.csv не найден. Проверьте путь к файлу.\")\n",
    "    # Здесь можно либо остановить выполнение, либо попытаться загрузить из другого места\n",
    "    # Для примера, если файл не найден, создадим заглушку DataFrame, чтобы код не падал дальше.\n",
    "    # В реальном проекте здесь должно быть корректное завершение или обработка ошибки.\n",
    "    data = pd.DataFrame() # Заглушка\n",
    "\n",
    "if not data.empty:\n",
    "    print(\"Данные успешно загружены.\")\n",
    "    print(\"Размер исходных данных:\", data.shape)\n",
    "    print(\"Первые 5 строк:\")\n",
    "    print(data.head())\n",
    "\n",
    "    # Анализ пропусков\n",
    "    nan_data_stats = (data.isnull().mean() * 100).reset_index()\n",
    "    nan_data_stats.columns = [\"column_name\", \"percentage\"]\n",
    "    nan_data_stats.sort_values(\"percentage\", ascending=False, inplace=True)\n",
    "    print(\"\\nПроцент пропусков в столбцах (топ 24):\")\n",
    "    print(nan_data_stats.head(24))\n",
    "\n",
    "    # Удаление строк, где целевая переменная 'worldwide' отсутствует\n",
    "    data_initial_rows = len(data)\n",
    "    data = data.dropna(subset=['worldwide'])\n",
    "    print(f\"\\nУдалено {data_initial_rows - len(data)} строк из-за отсутствия значения в 'worldwide'.\")\n",
    "    print(\"Размер данных после удаления строк с NaN в 'worldwide':\", data.shape)\n",
    "else:\n",
    "    print(\"Не удалось загрузить данные. Дальнейшее выполнение скрипта может быть некорректным.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47a2742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Тестовые данные сохранены в test.csv (размер: (1714, 24))\n",
      "Обучающие данные (размер: (3998, 24))\n",
      "\n",
      "Столбцы, удаленные из train_data: ['movie_id', 'movie_title', 'link']\n",
      "Первые 5 строк train_data после удаления столбцов:\n",
      "      movie_year             director              writer            producer  \\\n",
      "4482        2008          Sanaa Hamri  Elizabeth Chandler  Debra Martin Chase   \n",
      "4803        2014          R.J. Cutler        Shauna Cross    Alison Greenspan   \n",
      "4890        2016       Sharon Maguire      Helen Fielding           Tim Bevan   \n",
      "5509        2016        Travis Knight         Marc Haimes       Travis Knight   \n",
      "2124        2015  Alfonso Gomez-Rejon       Jesse Andrews       Jeremy Dawson   \n",
      "\n",
      "              composer   cinematographer        main_actor_1   main_actor_2  \\\n",
      "4482    Rachel Portman       Jim Denault     America Ferrera  Alexis Bledel   \n",
      "4803    Heitor Pereira    John de Borman  Chloë Grace Moretz  Mireille Enos   \n",
      "4890   Craig Armstrong       Andrew Dunn     Renée Zellweger    Gemma Jones   \n",
      "5509  Dario Marianelli  Frank Passingham     Charlize Theron  Art Parkinson   \n",
      "2124         Brian Eno  Chung-hoon Chung         Thomas Mann       RJ Cyler   \n",
      "\n",
      "             main_actor_3    main_actor_4    budget    domestic  \\\n",
      "4482        Amber Tamblyn    Blake Lively  27000000  44089964.0   \n",
      "4803       Jamie Blackley  Joshua Leonard  11000000  50474843.0   \n",
      "4890        Jim Broadbent  Sally Phillips  35000000  24252420.0   \n",
      "5509  Matthew McConaughey   Ralph Fiennes  60000000  48023088.0   \n",
      "2124         Olivia Cooke   Nick Offerman   8000000   6758416.0   \n",
      "\n",
      "      international    worldwide   mpaa     run_time genre_1    genre_2  \\\n",
      "4482       262453.0   44352417.0  PG-13  1 hr 59 min  Comedy      Drama   \n",
      "4803     27800000.0   78274843.0  PG-13  1 hr 47 min   Drama    Fantasy   \n",
      "4890    187700000.0  211952420.0      R   2 hr 3 min  Comedy      Drama   \n",
      "5509     28226350.0   76249438.0     PG  1 hr 41 min  Action  Adventure   \n",
      "2124      2316333.0    9074749.0  PG-13  1 hr 45 min  Comedy      Drama   \n",
      "\n",
      "        genre_3  genre_4         distributor  \n",
      "4482    Romance      NaN        Warner Bros.  \n",
      "4803      Music  Romance        Warner Bros.  \n",
      "4890    Romance      NaN  Universal Pictures  \n",
      "5509  Animation   Family      Focus Features  \n",
      "2124    Romance      NaN                 NaN  \n"
     ]
    }
   ],
   "source": [
    "if not data.empty:\n",
    "    # Разделение на обучающую и тестовую выборки\n",
    "    # Тестовая выборка будет сохранена в test.csv для будущего использования скриптом test.py\n",
    "    train_data, test_data_for_file = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Сохранение тестовых данных в файл test.csv\n",
    "    # Этот файл будет использоваться отдельным скриптом test.py для предсказаний\n",
    "    test_data_for_file.to_csv(\"test.csv\", index=False)\n",
    "    print(f\"\\nТестовые данные сохранены в test.csv (размер: {test_data_for_file.shape})\")\n",
    "    print(f\"Обучающие данные (размер: {train_data.shape})\")\n",
    "\n",
    "    # Сохраним оригинальное название фильма из обучающей выборки для возможного анализа\n",
    "    train_movie_title_original = train_data['movie_title'].copy() # Сохраняем до удаления столбца\n",
    "\n",
    "    # Определение столбцов для удаления (эти столбцы не будут использоваться для обучения)\n",
    "    columns_to_drop_initial = ['movie_id', 'movie_title', 'link']\n",
    "    train_data = train_data.drop(columns=columns_to_drop_initial, errors='ignore') # errors='ignore' если какой-то колонки уже нет\n",
    "    print(\"\\nСтолбцы, удаленные из train_data:\", columns_to_drop_initial)\n",
    "    print(\"Первые 5 строк train_data после удаления столбцов:\")\n",
    "    print(train_data.head())\n",
    "else:\n",
    "    print(\"Пропуск разделения данных, так как исходные данные не были загружены.\")\n",
    "    train_data = pd.DataFrame() # Заглушка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55885cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация словарей для сохранения карт преобразований\n",
    "# Эти словари будут заполняться ПО ХОДУ предобработки данных\n",
    "# и затем сохранены в JSON для использования в test.py\n",
    "\n",
    "experience_maps_to_save = {}\n",
    "grouped_imputation_maps_to_save = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ea25cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Создание признаков опыта для съемочной группы...\n",
      "  Создан признак director_experience\n",
      "  Создан признак writer_experience\n",
      "  Создан признак producer_experience\n",
      "  Создан признак composer_experience\n",
      "  Создан признак cinematographer_experience\n",
      "\n",
      "Создание признаков опыта для актеров...\n",
      "  Создан признак main_actor_1_experience\n",
      "  Создан признак main_actor_2_experience\n",
      "  Создан признак main_actor_3_experience\n",
      "  Создан признак main_actor_4_experience\n",
      "  Создан признак cast_popularity\n",
      "\n",
      "Столбец 'run_time' преобразован в минуты.\n",
      "\n",
      "Первые 5 строк train_data после создания признаков:\n",
      "      movie_year             director              writer            producer  \\\n",
      "4482        2008          Sanaa Hamri  Elizabeth Chandler  Debra Martin Chase   \n",
      "4803        2014          R.J. Cutler        Shauna Cross    Alison Greenspan   \n",
      "4890        2016       Sharon Maguire      Helen Fielding           Tim Bevan   \n",
      "5509        2016        Travis Knight         Marc Haimes       Travis Knight   \n",
      "2124        2015  Alfonso Gomez-Rejon       Jesse Andrews       Jeremy Dawson   \n",
      "\n",
      "              composer   cinematographer        main_actor_1   main_actor_2  \\\n",
      "4482    Rachel Portman       Jim Denault     America Ferrera  Alexis Bledel   \n",
      "4803    Heitor Pereira    John de Borman  Chloë Grace Moretz  Mireille Enos   \n",
      "4890   Craig Armstrong       Andrew Dunn     Renée Zellweger    Gemma Jones   \n",
      "5509  Dario Marianelli  Frank Passingham     Charlize Theron  Art Parkinson   \n",
      "2124         Brian Eno  Chung-hoon Chung         Thomas Mann       RJ Cyler   \n",
      "\n",
      "             main_actor_3    main_actor_4    budget    domestic  \\\n",
      "4482        Amber Tamblyn    Blake Lively  27000000  44089964.0   \n",
      "4803       Jamie Blackley  Joshua Leonard  11000000  50474843.0   \n",
      "4890        Jim Broadbent  Sally Phillips  35000000  24252420.0   \n",
      "5509  Matthew McConaughey   Ralph Fiennes  60000000  48023088.0   \n",
      "2124         Olivia Cooke   Nick Offerman   8000000   6758416.0   \n",
      "\n",
      "      international    worldwide   mpaa  run_time genre_1    genre_2  \\\n",
      "4482       262453.0   44352417.0  PG-13       119  Comedy      Drama   \n",
      "4803     27800000.0   78274843.0  PG-13       107   Drama    Fantasy   \n",
      "4890    187700000.0  211952420.0      R       123  Comedy      Drama   \n",
      "5509     28226350.0   76249438.0     PG       101  Action  Adventure   \n",
      "2124      2316333.0    9074749.0  PG-13       105  Comedy      Drama   \n",
      "\n",
      "        genre_3  genre_4         distributor  director_experience  \\\n",
      "4482    Romance      NaN        Warner Bros.                    1   \n",
      "4803      Music  Romance        Warner Bros.                    1   \n",
      "4890    Romance      NaN  Universal Pictures                    3   \n",
      "5509  Animation   Family      Focus Features                    1   \n",
      "2124    Romance      NaN                 NaN                    2   \n",
      "\n",
      "      writer_experience  producer_experience  composer_experience  \\\n",
      "4482                1.0                  7.0                 22.0   \n",
      "4803                2.0                  1.0                 15.0   \n",
      "4890                5.0                 43.0                 26.0   \n",
      "5509                1.0                  2.0                 10.0   \n",
      "2124                4.0                  2.0                  3.0   \n",
      "\n",
      "      cinematographer_experience  main_actor_1_experience  \\\n",
      "4482                        13.0                        1   \n",
      "4803                        10.0                        5   \n",
      "4890                        22.0                        7   \n",
      "5509                         3.0                       13   \n",
      "2124                         6.0                        2   \n",
      "\n",
      "      main_actor_2_experience  main_actor_3_experience  \\\n",
      "4482                        3                        1   \n",
      "4803                        1                        1   \n",
      "4890                        2                        3   \n",
      "5509                        1                        1   \n",
      "2124                        2                        2   \n",
      "\n",
      "      main_actor_4_experience  cast_popularity  \n",
      "4482                      3.0              8.0  \n",
      "4803                      1.0              8.0  \n",
      "4890                      2.0             14.0  \n",
      "5509                      6.0             21.0  \n",
      "2124                      4.0             10.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ls/btrdy60n12n_lk3plpt7wqlh0000gn/T/ipykernel_29645/3883809262.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[f\"{col}_experience\"].fillna(0, inplace=True) # Заполняем NaN (если значение не встретилось) нулем\n",
      "/var/folders/ls/btrdy60n12n_lk3plpt7wqlh0000gn/T/ipykernel_29645/3883809262.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[f\"{col}_experience\"].fillna(0, inplace=True) # Заполняем NaN (если значение не встретилось) нулем\n",
      "/var/folders/ls/btrdy60n12n_lk3plpt7wqlh0000gn/T/ipykernel_29645/3883809262.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[f\"{col}_experience\"].fillna(0, inplace=True) # Заполняем NaN (если значение не встретилось) нулем\n",
      "/var/folders/ls/btrdy60n12n_lk3plpt7wqlh0000gn/T/ipykernel_29645/3883809262.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[f\"{col}_experience\"].fillna(0, inplace=True) # Заполняем NaN (если значение не встретилось) нулем\n",
      "/var/folders/ls/btrdy60n12n_lk3plpt7wqlh0000gn/T/ipykernel_29645/3883809262.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[f\"{col}_experience\"].fillna(0, inplace=True) # Заполняем NaN (если значение не встретилось) нулем\n",
      "/var/folders/ls/btrdy60n12n_lk3plpt7wqlh0000gn/T/ipykernel_29645/3883809262.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[experience_col_name].fillna(0, inplace=True)\n",
      "/var/folders/ls/btrdy60n12n_lk3plpt7wqlh0000gn/T/ipykernel_29645/3883809262.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[experience_col_name].fillna(0, inplace=True)\n",
      "/var/folders/ls/btrdy60n12n_lk3plpt7wqlh0000gn/T/ipykernel_29645/3883809262.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[experience_col_name].fillna(0, inplace=True)\n",
      "/var/folders/ls/btrdy60n12n_lk3plpt7wqlh0000gn/T/ipykernel_29645/3883809262.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[experience_col_name].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "if not train_data.empty:\n",
    "    # 1. Создание признаков \"опыта\" для съемочной группы\n",
    "    personnel_cols_for_experience = [\"director\", \"writer\", \"producer\", \"composer\", \"cinematographer\"]\n",
    "    print(\"\\nСоздание признаков опыта для съемочной группы...\")\n",
    "    for col in personnel_cols_for_experience:\n",
    "        if col in train_data.columns:\n",
    "            counts = train_data[col].value_counts()\n",
    "            experience_maps_to_save[f\"{col}_experience_map\"] = counts.to_dict() # СОХРАНЯЕМ КАРТУ\n",
    "            train_data[f\"{col}_experience\"] = train_data[col].map(counts)\n",
    "            train_data[f\"{col}_experience\"].fillna(0, inplace=True) # Заполняем NaN (если значение не встретилось) нулем\n",
    "            print(f\"  Создан признак {col}_experience\")\n",
    "        else:\n",
    "            print(f\"  Предупреждение: столбец {col} не найден в train_data для создания опыта.\")\n",
    "\n",
    "    # 2. Создание признаков \"опыта\" для главных актеров и суммарной \"популярности\" состава\n",
    "    actor_experience_cols = []\n",
    "    print(\"\\nСоздание признаков опыта для актеров...\")\n",
    "    for i in range(1, 5): # main_actor_1, main_actor_2, main_actor_3, main_actor_4\n",
    "        col = f\"main_actor_{i}\"\n",
    "        if col in train_data.columns:\n",
    "            counts = train_data[col].value_counts()\n",
    "            experience_maps_to_save[f\"{col}_experience_map\"] = counts.to_dict() # СОХРАНЯЕМ КАРТУ\n",
    "            experience_col_name = f\"{col}_experience\"\n",
    "            train_data[experience_col_name] = train_data[col].map(counts)\n",
    "            train_data[experience_col_name].fillna(0, inplace=True)\n",
    "            actor_experience_cols.append(experience_col_name)\n",
    "            print(f\"  Создан признак {experience_col_name}\")\n",
    "        else:\n",
    "            print(f\"  Предупреждение: столбец {col} не найден в train_data для создания опыта.\")\n",
    "\n",
    "    if actor_experience_cols:\n",
    "        train_data[\"cast_popularity\"] = train_data[actor_experience_cols].sum(axis=1)\n",
    "        print(\"  Создан признак cast_popularity\")\n",
    "    else:\n",
    "        train_data[\"cast_popularity\"] = 0 # Если актеров нет, популярность 0\n",
    "        print(\"  Признак cast_popularity установлен в 0 (актерские колонки не найдены/обработаны).\")\n",
    "\n",
    "\n",
    "    # 3. Преобразование 'run_time' в минуты\n",
    "    def convert_runtime_to_minutes(value):\n",
    "        match = re.match(r'(?:(\\d+)\\s*hr)?\\s*(?:(\\d+)\\s*min)?', str(value))\n",
    "        if match:\n",
    "            hours = int(match.group(1)) if match.group(1) else 0\n",
    "            minutes = int(match.group(2)) if match.group(2) else 0\n",
    "            return hours * 60 + minutes\n",
    "        return None # если формат не распознан или значение NaN\n",
    "\n",
    "    if 'run_time' in train_data.columns:\n",
    "        train_data['run_time'] = train_data['run_time'].apply(convert_runtime_to_minutes)\n",
    "        print(\"\\nСтолбец 'run_time' преобразован в минуты.\")\n",
    "    else:\n",
    "        print(\"\\nПредупреждение: столбец 'run_time' не найден в train_data.\")\n",
    "\n",
    "    print(\"\\nПервые 5 строк train_data после создания признаков:\")\n",
    "    print(train_data.head())\n",
    "else:\n",
    "    print(\"Пропуск Feature Engineering, так как train_data пуст.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af679859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Числовые пропуски в ['movie_year', 'budget', 'domestic', 'international', 'run_time', 'director_experience', 'writer_experience', 'producer_experience', 'composer_experience', 'cinematographer_experience', 'main_actor_1_experience', 'main_actor_2_experience', 'main_actor_3_experience', 'main_actor_4_experience', 'cast_popularity'] заполнены медианой.\n",
      "\n",
      "Групповая импутация для категориальных признаков (модой по 'director')...\n",
      "  Пропуски в 'cinematographer' заполнены модой по группам 'director'.\n",
      "  Пропуски в 'composer' заполнены модой по группам 'director'.\n",
      "  Пропуски в 'producer' заполнены модой по группам 'director'.\n",
      "  Пропуски в 'writer' заполнены модой по группам 'director'.\n",
      "\n",
      "Заполнение специфических пропусков значением 'Unknown'...\n",
      "  Пропуски в 'genre_2' заполнены 'Unknown'.\n",
      "  Пропуски в 'genre_3' заполнены 'Unknown'.\n",
      "  Пропуски в 'genre_4' заполнены 'Unknown'.\n",
      "  Пропуски в 'main_actor_4' заполнены 'Unknown'.\n",
      "\n",
      "Оставшиеся категориальные пропуски в ['director', 'writer', 'producer', 'composer', 'cinematographer', 'main_actor_1', 'main_actor_2', 'main_actor_3', 'main_actor_4', 'mpaa', 'genre_1', 'genre_2', 'genre_3', 'genre_4', 'distributor'] заполнены модой.\n",
      "\n",
      "Процент пропусков после всех этапов импутации:\n",
      "Empty DataFrame\n",
      "Columns: [column_name, percentage]\n",
      "Index: []\n",
      "Все пропуски в train_data устранены.\n"
     ]
    }
   ],
   "source": [
    "if not train_data.empty:\n",
    "    # 1. Импутация числовых признаков медианой\n",
    "    num_cols_for_imputation = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    # Исключаем целевую переменную 'worldwide', если она еще числовая и попала в список\n",
    "    if 'worldwide' in num_cols_for_imputation:\n",
    "        num_cols_for_imputation.remove('worldwide')\n",
    "    \n",
    "    if num_cols_for_imputation: # Если есть числовые колонки для импутации\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        train_data[num_cols_for_imputation] = num_imputer.fit_transform(train_data[num_cols_for_imputation])\n",
    "        print(f\"\\nЧисловые пропуски в {num_cols_for_imputation} заполнены медианой.\")\n",
    "    else:\n",
    "        print(\"\\nНет числовых колонок для импутации (кроме, возможно, 'worldwide').\")\n",
    "        num_imputer = None # Инициализируем на случай, если не создался\n",
    "\n",
    "    # 2. Групповая импутация для некоторых категориальных признаков (модой по 'director')\n",
    "    # Эти столбцы должны быть категориальными (object)\n",
    "    cols_to_fill_by_director_mode = ['cinematographer', 'composer', 'producer', 'writer']\n",
    "    print(\"\\nГрупповая импутация для категориальных признаков (модой по 'director')...\")\n",
    "    if 'director' in train_data.columns:\n",
    "        for col_to_impute in cols_to_fill_by_director_mode:\n",
    "            if col_to_impute in train_data.columns:\n",
    "                # Создаем карту: director -> mode_of_col_to_impute\n",
    "                director_to_mode_map = train_data.groupby('director')[col_to_impute].apply(\n",
    "                    lambda x: x.mode().iloc[0] if not x.mode().empty and not x.mode().isnull().all() else np.nan\n",
    "                )\n",
    "                # Сохраняем карту для артефактов\n",
    "                grouped_imputation_maps_to_save[f\"{col_to_impute}_director_mode_map\"] = director_to_mode_map.to_dict()\n",
    "                \n",
    "                # Применяем карту для заполнения пропусков\n",
    "                mapped_modes = train_data['director'].map(director_to_mode_map)\n",
    "                train_data[col_to_impute] = train_data[col_to_impute].fillna(mapped_modes)\n",
    "                print(f\"  Пропуски в '{col_to_impute}' заполнены модой по группам 'director'.\")\n",
    "            else:\n",
    "                print(f\"  Предупреждение: столбец {col_to_impute} не найден для групповой импутации.\")\n",
    "    else:\n",
    "        print(\"  Предупреждение: столбец 'director' не найден, групповая импутация не будет выполнена.\")\n",
    "\n",
    "    # 3. Заполнение специфических пропусков значением 'Unknown'\n",
    "    cols_to_fill_unknown_specific = ['genre_2', 'genre_3', 'genre_4', 'main_actor_4']\n",
    "    print(\"\\nЗаполнение специфических пропусков значением 'Unknown'...\")\n",
    "    for col in cols_to_fill_unknown_specific:\n",
    "        if col in train_data.columns:\n",
    "            train_data[col] = train_data[col].fillna('Unknown')\n",
    "            print(f\"  Пропуски в '{col}' заполнены 'Unknown'.\")\n",
    "        else:\n",
    "            print(f\"  Предупреждение: столбец {col} не найден для заполнения 'Unknown'.\")\n",
    "\n",
    "\n",
    "    # 4. Импутация оставшихся категориальных признаков модой\n",
    "    # Важно: cat_cols_for_imputation должен определяться ДО кодирования (OHE, Target Encoding)\n",
    "    cat_cols_for_imputation = train_data.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    if cat_cols_for_imputation:\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        train_data[cat_cols_for_imputation] = cat_imputer.fit_transform(train_data[cat_cols_for_imputation])\n",
    "        print(f\"\\nОставшиеся категориальные пропуски в {cat_cols_for_imputation} заполнены модой.\")\n",
    "    else:\n",
    "        print(\"\\nНет категориальных колонок для общей импутации модой.\")\n",
    "        cat_imputer = None # Инициализируем\n",
    "\n",
    "    # Проверка пропусков после всех импутаций\n",
    "    print(\"\\nПроцент пропусков после всех этапов импутации:\")\n",
    "    nan_after_imputation = (train_data.isnull().mean() * 100).reset_index()\n",
    "    nan_after_imputation.columns = [\"column_name\", \"percentage\"]\n",
    "    print(nan_after_imputation[nan_after_imputation[\"percentage\"] > 0])\n",
    "    if nan_after_imputation[\"percentage\"].sum() == 0:\n",
    "        print(\"Все пропуски в train_data устранены.\")\n",
    "else:\n",
    "    print(\"Пропуск обработки пропусков, так как train_data пуст.\")\n",
    "    num_imputer = None\n",
    "    cat_imputer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f777e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Статистика по категориальным столбцам (до кодирования):\n",
      "             Column  Unique_Count\n",
      "8      main_actor_4          2136\n",
      "7      main_actor_3          1898\n",
      "1            writer          1863\n",
      "6      main_actor_2          1564\n",
      "2          producer          1385\n",
      "0          director          1380\n",
      "5      main_actor_1          1173\n",
      "4   cinematographer           787\n",
      "3          composer           713\n",
      "14      distributor           165\n",
      "11          genre_2            21\n",
      "12          genre_3            21\n",
      "13          genre_4            18\n",
      "10          genre_1            15\n",
      "9              mpaa             5\n",
      "\n",
      "Столбцы, выбранные для Target Encoding: ['main_actor_4', 'main_actor_3', 'writer', 'main_actor_2', 'producer', 'director', 'main_actor_1', 'cinematographer', 'composer', 'distributor']\n",
      "Столбцы, выбранные для One-Hot Encoding: ['genre_2', 'genre_3', 'genre_4', 'genre_1', 'mpaa']\n",
      "\n",
      "Выполнено One-Hot Encoding для: ['genre_2', 'genre_3', 'genre_4', 'genre_1', 'mpaa'].\n",
      "Размер train_data изменился с (3998, 31) на (3998, 106)\n",
      "\n",
      "Выполнено Target Encoding для: ['main_actor_4', 'main_actor_3', 'writer', 'main_actor_2', 'producer', 'director', 'main_actor_1', 'cinematographer', 'composer', 'distributor'].\n",
      "\n",
      "Первые 5 строк train_data после кодирования:\n",
      "      movie_year      director        writer      producer      composer  \\\n",
      "4482      2008.0  1.345182e+08  1.345182e+08  1.348617e+08  1.045484e+08   \n",
      "4803      2014.0  1.389318e+08  1.337451e+08  1.389318e+08  2.625639e+08   \n",
      "4890      2016.0  1.614849e+08  1.661032e+08  1.295603e+08  1.379337e+08   \n",
      "5509      2016.0  1.386682e+08  1.386682e+08  1.400165e+08  1.417198e+08   \n",
      "2124      2015.0  1.282969e+08  1.247797e+08  1.282969e+08  1.308975e+08   \n",
      "\n",
      "      cinematographer  main_actor_1  main_actor_2  main_actor_3  main_actor_4  \\\n",
      "4482     1.248082e+08  1.345182e+08  1.317527e+08  1.345182e+08  1.317527e+08   \n",
      "4803     1.309102e+08  1.380674e+08  1.389318e+08  1.389318e+08  1.389318e+08   \n",
      "4890     1.316244e+08  1.558859e+08  1.570753e+08  1.506852e+08  1.570753e+08   \n",
      "5509     1.417403e+08  1.161474e+08  1.386682e+08  1.386682e+08  1.559626e+08   \n",
      "2124     1.700476e+08  1.282969e+08  1.282969e+08  1.282969e+08  1.517334e+08   \n",
      "\n",
      "          budget    domestic  international    worldwide  run_time  \\\n",
      "4482  27000000.0  44089964.0       262453.0   44352417.0     119.0   \n",
      "4803  11000000.0  50474843.0     27800000.0   78274843.0     107.0   \n",
      "4890  35000000.0  24252420.0    187700000.0  211952420.0     123.0   \n",
      "5509  60000000.0  48023088.0     28226350.0   76249438.0     101.0   \n",
      "2124   8000000.0   6758416.0      2316333.0    9074749.0     105.0   \n",
      "\n",
      "       distributor  director_experience  writer_experience  \\\n",
      "4482  1.607434e+08                  1.0                1.0   \n",
      "4803  1.607434e+08                  1.0                2.0   \n",
      "4890  1.844454e+08                  3.0                5.0   \n",
      "5509  8.194362e+07                  1.0                1.0   \n",
      "2124  1.607434e+08                  2.0                4.0   \n",
      "\n",
      "      producer_experience  composer_experience  cinematographer_experience  \\\n",
      "4482                  7.0                 22.0                        13.0   \n",
      "4803                  1.0                 15.0                        10.0   \n",
      "4890                 43.0                 26.0                        22.0   \n",
      "5509                  2.0                 10.0                         3.0   \n",
      "2124                  2.0                  3.0                         6.0   \n",
      "\n",
      "      main_actor_1_experience  main_actor_2_experience  \\\n",
      "4482                      1.0                      3.0   \n",
      "4803                      5.0                      1.0   \n",
      "4890                      7.0                      2.0   \n",
      "5509                     13.0                      1.0   \n",
      "2124                      2.0                      2.0   \n",
      "\n",
      "      main_actor_3_experience  main_actor_4_experience  cast_popularity  \\\n",
      "4482                      1.0                      3.0              8.0   \n",
      "4803                      1.0                      1.0              8.0   \n",
      "4890                      3.0                      2.0             14.0   \n",
      "5509                      1.0                      6.0             21.0   \n",
      "2124                      2.0                      4.0             10.0   \n",
      "\n",
      "      genre_2_Adventure  genre_2_Animation  genre_2_Biography  genre_2_Comedy  \\\n",
      "4482              False              False              False           False   \n",
      "4803              False              False              False           False   \n",
      "4890              False              False              False           False   \n",
      "5509               True              False              False           False   \n",
      "2124              False              False              False           False   \n",
      "\n",
      "      genre_2_Crime  genre_2_Documentary  genre_2_Drama  genre_2_Family  \\\n",
      "4482          False                False           True           False   \n",
      "4803          False                False          False           False   \n",
      "4890          False                False           True           False   \n",
      "5509          False                False          False           False   \n",
      "2124          False                False           True           False   \n",
      "\n",
      "      genre_2_Fantasy  genre_2_History  genre_2_Horror  genre_2_Music  \\\n",
      "4482            False            False           False          False   \n",
      "4803             True            False           False          False   \n",
      "4890            False            False           False          False   \n",
      "5509            False            False           False          False   \n",
      "2124            False            False           False          False   \n",
      "\n",
      "      genre_2_Musical  genre_2_Mystery  genre_2_Romance  genre_2_Sci-Fi  \\\n",
      "4482            False            False            False           False   \n",
      "4803            False            False            False           False   \n",
      "4890            False            False            False           False   \n",
      "5509            False            False            False           False   \n",
      "2124            False            False            False           False   \n",
      "\n",
      "      genre_2_Sport  genre_2_Thriller  genre_2_Unknown  genre_2_War  \\\n",
      "4482          False             False            False        False   \n",
      "4803          False             False            False        False   \n",
      "4890          False             False            False        False   \n",
      "5509          False             False            False        False   \n",
      "2124          False             False            False        False   \n",
      "\n",
      "      genre_2_Western  genre_3_Animation  genre_3_Biography  genre_3_Comedy  \\\n",
      "4482            False              False              False           False   \n",
      "4803            False              False              False           False   \n",
      "4890            False              False              False           False   \n",
      "5509            False               True              False           False   \n",
      "2124            False              False              False           False   \n",
      "\n",
      "      genre_3_Crime  genre_3_Documentary  genre_3_Drama  genre_3_Family  \\\n",
      "4482          False                False          False           False   \n",
      "4803          False                False          False           False   \n",
      "4890          False                False          False           False   \n",
      "5509          False                False          False           False   \n",
      "2124          False                False          False           False   \n",
      "\n",
      "      genre_3_Fantasy  genre_3_History  genre_3_Horror  genre_3_Music  \\\n",
      "4482            False            False           False          False   \n",
      "4803            False            False           False           True   \n",
      "4890            False            False           False          False   \n",
      "5509            False            False           False          False   \n",
      "2124            False            False           False          False   \n",
      "\n",
      "      genre_3_Musical  genre_3_Mystery  genre_3_News  genre_3_Romance  \\\n",
      "4482            False            False         False             True   \n",
      "4803            False            False         False            False   \n",
      "4890            False            False         False             True   \n",
      "5509            False            False         False            False   \n",
      "2124            False            False         False             True   \n",
      "\n",
      "      genre_3_Sci-Fi  genre_3_Sport  genre_3_Thriller  genre_3_Unknown  \\\n",
      "4482           False          False             False            False   \n",
      "4803           False          False             False            False   \n",
      "4890           False          False             False            False   \n",
      "5509           False          False             False            False   \n",
      "2124           False          False             False            False   \n",
      "\n",
      "      genre_3_War  genre_3_Western  genre_4_Comedy  genre_4_Crime  \\\n",
      "4482        False            False           False          False   \n",
      "4803        False            False           False          False   \n",
      "4890        False            False           False          False   \n",
      "5509        False            False           False          False   \n",
      "2124        False            False           False          False   \n",
      "\n",
      "      genre_4_Drama  genre_4_Family  genre_4_Fantasy  genre_4_History  \\\n",
      "4482          False           False            False            False   \n",
      "4803          False           False            False            False   \n",
      "4890          False           False            False            False   \n",
      "5509          False            True            False            False   \n",
      "2124          False           False            False            False   \n",
      "\n",
      "      genre_4_Horror  genre_4_Music  genre_4_Musical  genre_4_Mystery  \\\n",
      "4482           False          False            False            False   \n",
      "4803           False          False            False            False   \n",
      "4890           False          False            False            False   \n",
      "5509           False          False            False            False   \n",
      "2124           False          False            False            False   \n",
      "\n",
      "      genre_4_News  genre_4_Romance  genre_4_Sci-Fi  genre_4_Sport  \\\n",
      "4482         False            False           False          False   \n",
      "4803         False             True           False          False   \n",
      "4890         False            False           False          False   \n",
      "5509         False            False           False          False   \n",
      "2124         False            False           False          False   \n",
      "\n",
      "      genre_4_Thriller  genre_4_Unknown  genre_4_War  genre_4_Western  \\\n",
      "4482             False             True        False            False   \n",
      "4803             False            False        False            False   \n",
      "4890             False             True        False            False   \n",
      "5509             False            False        False            False   \n",
      "2124             False             True        False            False   \n",
      "\n",
      "      genre_1_Action  genre_1_Adventure  genre_1_Animation  genre_1_Biography  \\\n",
      "4482           False              False              False              False   \n",
      "4803           False              False              False              False   \n",
      "4890           False              False              False              False   \n",
      "5509            True              False              False              False   \n",
      "2124           False              False              False              False   \n",
      "\n",
      "      genre_1_Comedy  genre_1_Crime  genre_1_Documentary  genre_1_Drama  \\\n",
      "4482            True          False                False          False   \n",
      "4803           False          False                False           True   \n",
      "4890            True          False                False          False   \n",
      "5509           False          False                False          False   \n",
      "2124            True          False                False          False   \n",
      "\n",
      "      genre_1_Family  genre_1_Fantasy  genre_1_Horror  genre_1_Music  \\\n",
      "4482           False            False           False          False   \n",
      "4803           False            False           False          False   \n",
      "4890           False            False           False          False   \n",
      "5509           False            False           False          False   \n",
      "2124           False            False           False          False   \n",
      "\n",
      "      genre_1_Mystery  genre_1_Romance  genre_1_Sci-Fi  mpaa_G  mpaa_NC-17  \\\n",
      "4482            False            False           False   False       False   \n",
      "4803            False            False           False   False       False   \n",
      "4890            False            False           False   False       False   \n",
      "5509            False            False           False   False       False   \n",
      "2124            False            False           False   False       False   \n",
      "\n",
      "      mpaa_PG  mpaa_PG-13  mpaa_R  \n",
      "4482    False        True   False  \n",
      "4803    False        True   False  \n",
      "4890    False       False    True  \n",
      "5509     True       False   False  \n",
      "2124    False        True   False  \n"
     ]
    }
   ],
   "source": [
    "# Блок 7: Кодирование категориальных признаков\n",
    "\n",
    "if not train_data.empty:\n",
    "    # Анализ категориальных признаков перед кодированием\n",
    "    cat_cols_original_types = train_data.select_dtypes(include=['object', 'category'])\n",
    "    if not cat_cols_original_types.empty:\n",
    "        cat_stats = pd.DataFrame({\n",
    "            'Column': cat_cols_original_types.columns,\n",
    "            'Unique_Count': [train_data[col].nunique() for col in cat_cols_original_types.columns]\n",
    "        })\n",
    "        cat_stats = cat_stats.sort_values(by='Unique_Count', ascending=False)\n",
    "        print(\"\\nСтатистика по категориальным столбцам (до кодирования):\")\n",
    "        print(cat_stats)\n",
    "    else:\n",
    "        print(\"\\nНет категориальных столбцов для анализа перед кодированием.\")\n",
    "\n",
    "    # Определение столбцов для One-Hot Encoding и Target Encoding\n",
    "    # Эти списки должны содержать имена столбцов, которые вы предполагаете кодировать этими методами.\n",
    "    # Код ниже отфильтрует их, оставив только существующие и подходящие по типу.\n",
    "    \n",
    "    candidate_target_encoding_cols = ['main_actor_4', 'main_actor_3', 'writer', 'main_actor_2', 'producer', 'director', 'main_actor_1', 'cinematographer', 'composer', 'distributor']\n",
    "    candidate_one_hot_cols = ['genre_2', 'genre_3', 'genre_4', 'genre_1', 'mpaa']\n",
    "\n",
    "    # Отбираем только те столбцы, что реально есть в train_data и являются категориальными (object)\n",
    "    # Важно: Target Encoding обычно применяется к столбцам с высокой кардинальностью, OHE - с низкой.\n",
    "    columns_for_target_encoding = []\n",
    "    for col in candidate_target_encoding_cols:\n",
    "        if col in train_data.columns and train_data[col].dtype == 'object':\n",
    "            columns_for_target_encoding.append(col)\n",
    "        elif col in train_data.columns:\n",
    "            print(f\"  Предупреждение: Столбец '{col}' для Target Encoding не является object, его тип: {train_data[col].dtype}. Пропущен.\")\n",
    "\n",
    "\n",
    "    columns_for_one_hot = []\n",
    "    for col in candidate_one_hot_cols:\n",
    "        if col in train_data.columns and train_data[col].dtype == 'object':\n",
    "            columns_for_one_hot.append(col)\n",
    "        elif col in train_data.columns:\n",
    "            print(f\"  Предупреждение: Столбец '{col}' для One-Hot Encoding не является object, его тип: {train_data[col].dtype}. Пропущен.\")\n",
    "\n",
    "\n",
    "    print(f\"\\nСтолбцы, выбранные для Target Encoding: {columns_for_target_encoding}\")\n",
    "    print(f\"Столбцы, выбранные для One-Hot Encoding: {columns_for_one_hot}\")\n",
    "\n",
    "    # 1. One-Hot Encoding\n",
    "    if columns_for_one_hot:\n",
    "        train_data_shape_before_ohe = train_data.shape\n",
    "        train_data = pd.get_dummies(train_data, columns=columns_for_one_hot, dummy_na=False) # dummy_na=False стандартно\n",
    "        print(f\"\\nВыполнено One-Hot Encoding для: {columns_for_one_hot}.\")\n",
    "        print(f\"Размер train_data изменился с {train_data_shape_before_ohe} на {train_data.shape}\")\n",
    "    else:\n",
    "        print(\"\\nНет столбцов для One-Hot Encoding.\")\n",
    "\n",
    "    # 2. Target Encoding\n",
    "    if columns_for_target_encoding:\n",
    "        if 'worldwide' in train_data.columns and not train_data['worldwide'].isnull().any():\n",
    "            target_encoder = ce.TargetEncoder(cols=columns_for_target_encoding, handle_missing='value', handle_unknown='value')\n",
    "            # handle_missing='value' и handle_unknown='value' заменят пропуски и неизвестные категории средним значением по таргету.\n",
    "            # Это может быть полезно, если в тестовых данных появятся новые категории.\n",
    "            train_data[columns_for_target_encoding] = target_encoder.fit_transform(train_data[columns_for_target_encoding], train_data['worldwide'])\n",
    "            print(f\"\\nВыполнено Target Encoding для: {columns_for_target_encoding}.\")\n",
    "        else:\n",
    "            print(\"\\nОшибка: Целевая переменная 'worldwide' отсутствует или содержит NaN. Target Encoding не выполнен.\")\n",
    "            target_encoder = None \n",
    "    else:\n",
    "        print(\"\\nНет столбцов для Target Encoding.\")\n",
    "        target_encoder = None \n",
    "\n",
    "    print(\"\\nПервые 5 строк train_data после кодирования:\")\n",
    "    print(train_data.head())\n",
    "    # print(\"Типы данных после кодирования:\") # Может быть очень длинный вывод\n",
    "    # print(train_data.info())\n",
    "else:\n",
    "    print(\"Пропуск кодирования признаков, так как train_data пуст.\")\n",
    "    target_encoder = None\n",
    "    columns_for_target_encoding = [] # Инициализация на случай, если train_data пуст\n",
    "    columns_for_one_hot = []       # Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f592e855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Признаки (X) и целевая переменная (y) разделены.\n",
      "Размер X: (3998, 105)\n",
      "Размер y: (3998,)\n",
      "\n",
      "Признаки X масштабированы с использованием StandardScaler.\n",
      "Размеры выборок для обучения/валидации: X_train: (3198, 105), X_val: (800, 105)\n"
     ]
    }
   ],
   "source": [
    "if not train_data.empty and 'worldwide' in train_data.columns:\n",
    "    # Отделение признаков (X) и целевой переменной (y)\n",
    "    X = train_data.drop(\"worldwide\", axis=1)\n",
    "    y = train_data[\"worldwide\"]\n",
    "    # y = np.log1p(train_data[\"worldwide\"]) # Если планируете логарифмировать цель\n",
    "\n",
    "    print(\"\\nПризнаки (X) и целевая переменная (y) разделены.\")\n",
    "    print(\"Размер X:\", X.shape)\n",
    "    print(\"Размер y:\", y.shape)\n",
    "\n",
    "    # Сохраним имена столбцов X для последующего использования (например, при сохранении артефактов)\n",
    "    final_feature_columns = X.columns.tolist() # Это столбцы ПОСЛЕ всех кодирований\n",
    "\n",
    "    # Масштабирование признаков\n",
    "    scaler = StandardScaler()\n",
    "    # scaler = MinMaxScaler() # Альтернативный вариант\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    print(\"\\nПризнаки X масштабированы с использованием StandardScaler.\")\n",
    "\n",
    "    # Разделение на обучающую и валидационную выборки (для оценки модели)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Размеры выборок для обучения/валидации: X_train: {X_train.shape}, X_val: {X_val.shape}\")\n",
    "\n",
    "else:\n",
    "    print(\"Пропуск подготовки X, y и масштабирования: train_data пуст или отсутствует 'worldwide'.\")\n",
    "    X, y, X_scaled, X_train, X_val, y_train, y_val = [None]*7 # Заглушки\n",
    "    final_feature_columns = []\n",
    "    scaler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82931b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Начало обучения модели XGBoost с RandomizedSearchCV...\n",
      "Запускается RandomizedSearchCV с 50 итерациями и 3 фолдами кросс-валидации...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "\n",
      "Лучшие параметры для XGBoost: {'subsample': 0.8, 'reg_lambda': 5, 'reg_alpha': 1, 'n_estimators': 700, 'max_depth': 8, 'learning_rate': 0.03, 'colsample_bytree': 0.8}\n",
      "\n",
      "Оценка лучшей модели XGBoost на валидационной выборке:\n",
      "  R²: 0.9988\n",
      "  MSE: 44882512123242.16\n",
      "  MAE: 3057717.82\n"
     ]
    }
   ],
   "source": [
    "# Блок 9: Обучение модели XGBoost с RandomizedSearchCV\n",
    "\n",
    "best_model = None \n",
    "\n",
    "if X_train is not None and y_train is not None:\n",
    "    print(\"\\nНачало обучения модели XGBoost с RandomizedSearchCV...\")\n",
    "    \n",
    "    param_dist_xgb = {\n",
    "        'n_estimators': [100, 300, 500, 700, 1000], # Добавлено 1000\n",
    "        'max_depth':    [4, 6, 8, 10, 12],          # Добавлено 12\n",
    "        'learning_rate':[0.01, 0.03, 0.05, 0.1],    # Добавлено 0.03\n",
    "        'subsample':    [0.6, 0.7, 0.8, 0.9, 1.0],  # Расширен диапазон\n",
    "        'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],# Расширен диапазон\n",
    "        'reg_alpha':    [0, 0.01, 0.1, 0.5, 1],     # Добавлен 0.01\n",
    "        'reg_lambda':   [0.5, 1, 2, 5]              # Изменен диапазон, убран 0\n",
    "    }\n",
    "\n",
    "    xgb_base_model = XGBRegressor(\n",
    "        random_state=42,\n",
    "        tree_method='hist', \n",
    "        n_jobs=-1 \n",
    "    )\n",
    "\n",
    "    random_search_xgb = RandomizedSearchCV(\n",
    "        estimator=xgb_base_model,\n",
    "        param_distributions=param_dist_xgb,\n",
    "        n_iter=50, # Увеличено с 25 до 50 (или даже 100, если есть время)\n",
    "        scoring='neg_mean_squared_error', \n",
    "        cv=3, \n",
    "        verbose=1,\n",
    "        n_jobs=1, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Запускается RandomizedSearchCV с {random_search_xgb.n_iter} итерациями и {random_search_xgb.cv} фолдами кросс-валидации...\")\n",
    "    random_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "    best_model = random_search_xgb.best_estimator_\n",
    "    print(\"\\nЛучшие параметры для XGBoost:\", random_search_xgb.best_params_)\n",
    "    \n",
    "    y_pred_val = best_model.predict(X_val)\n",
    "    r2_val = r2_score(y_val, y_pred_val)\n",
    "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "    mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "\n",
    "    print(f\"\\nОценка лучшей модели XGBoost на валидационной выборке:\")\n",
    "    print(f\"  R²: {r2_val:.4f}\")\n",
    "    print(f\"  MSE: {mse_val:.2f}\")\n",
    "    print(f\"  MAE: {mae_val:.2f}\")\n",
    "else:\n",
    "    print(\"Пропуск обучения модели: X_train или y_train не определены.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a42d398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- НАЧАЛО: СОХРАНЕНИЕ АРТЕФАКТОВ ---\n",
      "  Модель 'movie_box_office_model.joblib' сохранена.\n",
      "  Численный импьютер 'numerical_imputer.joblib' сохранен.\n",
      "  Категориальный импьютер 'categorical_imputer.joblib' сохранен.\n",
      "  Target Encoder 'target_encoder.joblib' сохранен.\n",
      "  Scaler 'scaler.joblib' сохранен.\n",
      "  Информация о столбцах и картах 'column_info.json' сохранена.\n",
      "--- АРТЕФАКТЫ УСПЕШНО СОХРАНЕНЫ ---\n"
     ]
    }
   ],
   "source": [
    "# Проверяем, что все необходимые компоненты существуют перед сохранением\n",
    "if best_model and num_imputer and cat_imputer and target_encoder and scaler and final_feature_columns:\n",
    "    print(\"\\n--- НАЧАЛО: СОХРАНЕНИЕ АРТЕФАКТОВ ---\")\n",
    "\n",
    "    # 1. Сохранение обученной модели\n",
    "    joblib.dump(best_model, \"movie_box_office_model.joblib\")\n",
    "    print(\"  Модель 'movie_box_office_model.joblib' сохранена.\")\n",
    "\n",
    "    # 2. Сохранение численного импьютера\n",
    "    joblib.dump(num_imputer, \"numerical_imputer.joblib\")\n",
    "    print(\"  Численный импьютер 'numerical_imputer.joblib' сохранен.\")\n",
    "\n",
    "    # 3. Сохранение категориального импьютера\n",
    "    joblib.dump(cat_imputer, \"categorical_imputer.joblib\")\n",
    "    print(\"  Категориальный импьютер 'categorical_imputer.joblib' сохранен.\")\n",
    "\n",
    "    # 4. Сохранение Target Encoder\n",
    "    joblib.dump(target_encoder, \"target_encoder.joblib\")\n",
    "    print(\"  Target Encoder 'target_encoder.joblib' сохранен.\")\n",
    "\n",
    "    # 5. Сохранение Scaler\n",
    "    joblib.dump(scaler, \"scaler.joblib\")\n",
    "    print(\"  Scaler 'scaler.joblib' сохранен.\")\n",
    "\n",
    "    # 6. Сохранение информации о столбцах и картах преобразований\n",
    "    \n",
    "    # Списки столбцов, определенные ранее (убедитесь, что они актуальны)\n",
    "    # columns_to_drop_initial уже определен\n",
    "    # num_cols_for_imputation уже определен\n",
    "    # cat_cols_for_imputation уже определен\n",
    "    # columns_for_target_encoding уже определен\n",
    "    # columns_for_one_hot уже определен\n",
    "    # final_feature_columns уже определен (это X.columns.tolist() после всех кодировок)\n",
    "    # cols_to_fill_by_director_mode уже определен\n",
    "    # cols_to_fill_unknown_specific уже определен\n",
    "\n",
    "    column_info = {\n",
    "        \"columns_to_drop_on_load\": columns_to_drop_initial, # Столбцы, которые удалялись в самом начале\n",
    "        \"num_cols_imputed_on_train\": num_cols_for_imputation, # Список числовых столбцов, к которым применялся num_imputer\n",
    "        \"cat_cols_imputed_on_train\": cat_cols_for_imputation, # Список категориальных столбцов, к которым применялся cat_imputer\n",
    "        \"target_encoded_cols\": columns_for_target_encoding, # Список столбцов для Target Encoding\n",
    "        \"one_hot_encoded_cols\": columns_for_one_hot, # Список столбцов для One-Hot Encoding\n",
    "        \"final_model_features\": final_feature_columns, # Итоговый список признаков для модели (порядок важен!)\n",
    "        \"experience_maps\": experience_maps_to_save, # Карты для признаков \"опыта\"\n",
    "        \"grouped_imputation_maps\": grouped_imputation_maps_to_save, # Карты для групповой импутации\n",
    "        \"group_impute_director_dependent_cols\": cols_to_fill_by_director_mode, # Столбцы, импьютируемые по 'director'\n",
    "        \"fill_unknown_cols\": cols_to_fill_unknown_specific, # Столбцы, заполняемые 'Unknown'\n",
    "        \"target_variable_name\": \"worldwide\" # Имя целевой переменной\n",
    "    }\n",
    "\n",
    "    # Очистка np.nan для JSON сериализации в картах\n",
    "    if \"experience_maps\" in column_info:\n",
    "        column_info[\"experience_maps\"] = {\n",
    "            map_name: {str(k): (None if pd.isna(v) else v) for k, v in map_dict.items()}\n",
    "            for map_name, map_dict in column_info[\"experience_maps\"].items()\n",
    "        }\n",
    "    if \"grouped_imputation_maps\" in column_info:\n",
    "         column_info[\"grouped_imputation_maps\"] = {\n",
    "            map_name: {str(k): (None if pd.isna(v) else v) for k, v in map_dict.items()}\n",
    "            for map_name, map_dict in column_info[\"grouped_imputation_maps\"].items()\n",
    "        }\n",
    "\n",
    "    with open(\"column_info.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(column_info, f, indent=4, ensure_ascii=False)\n",
    "    print(\"  Информация о столбцах и картах 'column_info.json' сохранена.\")\n",
    "\n",
    "    print(\"--- АРТЕФАКТЫ УСПЕШНО СОХРАНЕНЫ ---\")\n",
    "else:\n",
    "    print(\"\\n--- СОХРАНЕНИЕ АРТЕФАКТОВ ПРОПУЩЕНО ---\")\n",
    "    print(\"  Одна или несколько необходимых компонент (модель, импьютеры, кодеры, скейлер, списки столбцов) не были созданы.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cde289e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Загружен test.csv для финальной оценки (размер: (1714, 24))\n",
      "\n",
      "Финальная оценка модели на test.csv (загруженном из файла):\n",
      "  R²: 0.9956\n",
      "  MSE: 185828245543836.97\n",
      "  MAE: 7655874.56\n",
      "\n",
      "Примеры предсказаний на test.csv:\n",
      "                            Movie Title  Actual Worldwide Gross  \\\n",
      "0                 Rise of the Guardians             306941670.0   \n",
      "1              The Fast and the Furious             207284863.0   \n",
      "2     Dickie Roberts: Former Child Star              23769505.0   \n",
      "3                                 Dumbo             353284621.0   \n",
      "4                          The Predator             160542134.0   \n",
      "5                   Along Came a Spider             105178561.0   \n",
      "6                        Last Christmas             121550750.0   \n",
      "7  The Visual Bible: The Gospel of John               4078741.0   \n",
      "8                         Lilo & Stitch             273144151.0   \n",
      "9                     The Jungle Book 2             186303759.0   \n",
      "\n",
      "   Predicted Worldwide Gross  \n",
      "0                283145824.0  \n",
      "1                214135152.0  \n",
      "2                 23341492.0  \n",
      "3                353566592.0  \n",
      "4                160157632.0  \n",
      "5                103367584.0  \n",
      "6                120920704.0  \n",
      "7                  4078883.0  \n",
      "8                260534000.0  \n",
      "9                176998944.0  \n"
     ]
    }
   ],
   "source": [
    "# Загрузка test.csv, созданного ранее\n",
    "try:\n",
    "    final_test_df = pd.read_csv(\"test.csv\")\n",
    "    print(f\"\\nЗагружен test.csv для финальной оценки (размер: {final_test_df.shape})\")\n",
    "\n",
    "    # Сохраняем истинные значения 'worldwide' и названия фильмов для вывода\n",
    "    y_true_final_test = final_test_df['worldwide'].copy()\n",
    "    movie_titles_final_test = final_test_df['movie_title'].copy()\n",
    "    \n",
    "    # --- НАЧАЛО ПОВТОРЕНИЯ ПРЕДОБРАБОТКИ для test.csv ---\n",
    "    # Важно: здесь нужно ПОВТОРИТЬ все шаги предобработки, как для train_data,\n",
    "    # но используя .transform() для обученных объектов и сохраненные карты.\n",
    "\n",
    "    df_test_processed = final_test_df.drop(columns=columns_to_drop_initial, errors='ignore')\n",
    "\n",
    "    # 1. Feature Engineering (опыт) - используем сохраненные experience_maps_to_save\n",
    "    for col_personnel in personnel_cols_for_experience: # Из Блока 5\n",
    "        map_key = f\"{col_personnel}_experience_map\"\n",
    "        if col_personnel in df_test_processed.columns and map_key in experience_maps_to_save:\n",
    "            current_map = experience_maps_to_save[map_key]\n",
    "            df_test_processed[f\"{col_personnel}_experience\"] = df_test_processed[col_personnel].map(current_map).fillna(0)\n",
    "    \n",
    "    actor_exp_cols_test = []\n",
    "    for i_actor in range(1, 5):\n",
    "        col_actor = f\"main_actor_{i_actor}\"\n",
    "        map_key_actor = f\"{col_actor}_experience_map\"\n",
    "        if col_actor in df_test_processed.columns and map_key_actor in experience_maps_to_save:\n",
    "            current_map_actor = experience_maps_to_save[map_key_actor]\n",
    "            exp_col_name_actor = f\"{col_actor}_experience\"\n",
    "            df_test_processed[exp_col_name_actor] = df_test_processed[col_actor].map(current_map_actor).fillna(0)\n",
    "            actor_exp_cols_test.append(exp_col_name_actor)\n",
    "    if actor_exp_cols_test:\n",
    "        df_test_processed[\"cast_popularity\"] = df_test_processed[actor_exp_cols_test].sum(axis=1)\n",
    "    else:\n",
    "        df_test_processed[\"cast_popularity\"] = 0\n",
    "\n",
    "    # 2. run_time\n",
    "    if 'run_time' in df_test_processed.columns:\n",
    "        df_test_processed['run_time'] = df_test_processed['run_time'].apply(convert_runtime_to_minutes)\n",
    "\n",
    "    # 3. Numerical Imputation - используем обученный num_imputer\n",
    "    if num_imputer and any(col in df_test_processed.columns for col in num_cols_for_imputation):\n",
    "        cols_to_impute_test_num = [col for col in num_cols_for_imputation if col in df_test_processed.columns]\n",
    "        if cols_to_impute_test_num:\n",
    "             df_test_processed[cols_to_impute_test_num] = num_imputer.transform(df_test_processed[cols_to_impute_test_num])\n",
    "\n",
    "\n",
    "    # 4. Grouped Imputation - используем сохраненные grouped_imputation_maps_to_save\n",
    "    if 'director' in df_test_processed.columns:\n",
    "        for col_group_impute in cols_to_fill_by_director_mode: # Из Блока 6\n",
    "            map_key_group = f\"{col_group_impute}_director_mode_map\"\n",
    "            if col_group_impute in df_test_processed.columns and map_key_group in grouped_imputation_maps_to_save:\n",
    "                current_map_group = grouped_imputation_maps_to_save[map_key_group]\n",
    "                # ВАЖНО: ключи в current_map_group могут быть числами, если director был числовым.\n",
    "                # Преобразуем их в строки, если map был сохранен с str(k)\n",
    "                # Если map был сохранен с оригинальными типами, то str() не нужен\n",
    "                # current_map_group_fixed_keys = {str(k): v for k,v in current_map_group.items()}\n",
    "                # mapped_modes_test = df_test_processed['director'].map(current_map_group_fixed_keys)\n",
    "\n",
    "                # Если ключи в JSON были сохранены как строки (из-за str(k) в блоке сохранения)\n",
    "                # а значения в df_test_processed['director'] - числа, то map не сработает.\n",
    "                # Лучше при загрузке JSON обратно конвертировать ключи в числа, если нужно,\n",
    "                # или убедиться, что тип ключа в map совпадает с типом значений в столбце.\n",
    "                # Для простоты здесь предполагаем, что типы совпадают или map() обработает.\n",
    "                mapped_modes_test = df_test_processed['director'].map(current_map_group)\n",
    "                df_test_processed[col_group_impute] = df_test_processed[col_group_impute].fillna(mapped_modes_test)\n",
    "\n",
    "\n",
    "    # 5. Fill 'Unknown'\n",
    "    for col_fill_unknown in cols_to_fill_unknown_specific: # Из Блока 6\n",
    "        if col_fill_unknown in df_test_processed.columns:\n",
    "            df_test_processed[col_fill_unknown] = df_test_processed[col_fill_unknown].fillna('Unknown')\n",
    "    \n",
    "    # 6. Categorical Imputation - используем обученный cat_imputer\n",
    "    if cat_imputer and any(col in df_test_processed.columns for col in cat_cols_for_imputation):\n",
    "        cols_to_impute_test_cat = [col for col in cat_cols_for_imputation if col in df_test_processed.columns and df_test_processed[col].dtype == 'object']\n",
    "        if cols_to_impute_test_cat:\n",
    "            df_test_processed[cols_to_impute_test_cat] = cat_imputer.transform(df_test_processed[cols_to_impute_test_cat])\n",
    "\n",
    "    # 7. One-Hot Encoding - применяем get_dummies\n",
    "    if columns_for_one_hot: # Из Блока 7\n",
    "        cols_ohe_test = [col for col in columns_for_one_hot if col in df_test_processed.columns]\n",
    "        if cols_ohe_test:\n",
    "            df_test_processed = pd.get_dummies(df_test_processed, columns=cols_ohe_test, dummy_na=False)\n",
    "\n",
    "    # 8. Target Encoding - используем обученный target_encoder\n",
    "    if target_encoder and columns_for_target_encoding: # Из Блока 7\n",
    "        cols_te_test = [col for col in columns_for_target_encoding if col in df_test_processed.columns]\n",
    "        if cols_te_test:\n",
    "            df_test_processed[cols_te_test] = target_encoder.transform(df_test_processed[cols_te_test])\n",
    "            \n",
    "    # 9. Reindex - ВАЖНО: привести столбцы тестового набора в соответствие с обучающим\n",
    "    # `final_feature_columns` - это X.columns.tolist() из обучающего набора ПОСЛЕ всех кодировок\n",
    "    df_test_processed = df_test_processed.reindex(columns=final_feature_columns, fill_value=0)\n",
    "    \n",
    "    # Проверка на NaN перед масштабированием в тестовых данных\n",
    "    if df_test_processed.isnull().any().any():\n",
    "        print(\"\\nПРЕДУПРЕЖДЕНИЕ: Обнаружены NaN в тестовых данных ПОСЛЕ предобработки и ПЕРЕД масштабированием!\")\n",
    "        print(df_test_processed.isnull().sum()[df_test_processed.isnull().sum() > 0])\n",
    "        # Можно добавить принудительное заполнение нулями или другой стратегией, если это допустимо\n",
    "        # df_test_processed.fillna(0, inplace=True) \n",
    "        # print(\"NaN принудительно заменены на 0.\")\n",
    "\n",
    "\n",
    "    # 10. Scaling - используем обученный scaler\n",
    "    if scaler:\n",
    "        X_final_test_scaled = scaler.transform(df_test_processed)\n",
    "    else:\n",
    "        X_final_test_scaled = df_test_processed.values # Если скейлер не был создан (маловероятно)\n",
    "\n",
    "    # --- КОНЕЦ ПОВТОРЕНИЯ ПРЕДОБРАБОТКИ ---\n",
    "\n",
    "    # Предсказание на обработанных тестовых данных\n",
    "    if best_model and X_final_test_scaled is not None:\n",
    "        y_pred_final_test = best_model.predict(X_final_test_scaled)\n",
    "\n",
    "        # Оценка\n",
    "        r2_final = r2_score(y_true_final_test, y_pred_final_test)\n",
    "        mse_final = mean_squared_error(y_true_final_test, y_pred_final_test)\n",
    "        mae_final = mean_absolute_error(y_true_final_test, y_pred_final_test)\n",
    "\n",
    "        print(f\"\\nФинальная оценка модели на test.csv (загруженном из файла):\")\n",
    "        print(f\"  R²: {r2_final:.4f}\")\n",
    "        print(f\"  MSE: {mse_final:.2f}\")\n",
    "        print(f\"  MAE: {mae_final:.2f}\")\n",
    "\n",
    "        # Вывод нескольких примеров предсказаний\n",
    "        results_df = pd.DataFrame({\n",
    "            'Movie Title': movie_titles_final_test,\n",
    "            'Actual Worldwide Gross': y_true_final_test,\n",
    "            'Predicted Worldwide Gross': y_pred_final_test\n",
    "        })\n",
    "        print(\"\\nПримеры предсказаний на test.csv:\")\n",
    "        print(results_df.head(10))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\\nФайл test.csv не найден для финальной оценки в этом ноутбуке.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nПроизошла ошибка при финальной оценке на test.csv: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
